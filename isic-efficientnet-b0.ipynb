{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T21:28:19.604636Z","iopub.execute_input":"2024-08-21T21:28:19.605097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torchmetrics\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nfrom PIL import Image\nfrom torchvision import transforms\nfrom tqdm.notebook import tqdm_notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-24T07:37:04.514383Z","iopub.execute_input":"2024-08-24T07:37:04.515089Z","iopub.status.idle":"2024-08-24T07:37:04.520884Z","shell.execute_reply.started":"2024-08-24T07:37:04.515053Z","shell.execute_reply":"2024-08-24T07:37:04.519879Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-24T07:37:04.522220Z","iopub.execute_input":"2024-08-24T07:37:04.522549Z","iopub.status.idle":"2024-08-24T07:37:04.572097Z","shell.execute_reply.started":"2024-08-24T07:37:04.522508Z","shell.execute_reply":"2024-08-24T07:37:04.571037Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# class_sample_count = [100,1]\n# weights = 1 / torch.Tensor(class_sample_count)\n# weights = weights.double()\n# sampler = torch.utils.data.sampler.WeightedRandomSampler(\n# weights=weights,\n# num_samples=100000,\n# replacement=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T07:37:07.826712Z","iopub.execute_input":"2024-08-24T07:37:07.827090Z","iopub.status.idle":"2024-08-24T07:37:07.831990Z","shell.execute_reply.started":"2024-08-24T07:37:07.827059Z","shell.execute_reply":"2024-08-24T07:37:07.830702Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport h5py,io\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass HDF5Dataset(Dataset): #defining the dataset \n    def __init__(self, data, metadata, transform=None):\n        self.data = h5py.File(data, 'r') #creating data argument\n        if type(metadata) is pd.DataFrame:\n            self.metadata = metadata\n        else:\n            self.metadata = pd.read_csv(metadata)\n        self.transform = transform #creating transform argument \n\n    def __len__(self):\n        return len(self.metadata) #returns dataset \n\n    def __getitem__(self, idx):#gets image and label \n        img_name = self.metadata.isic_id[idx] #accesses image filepath \n        image = np.array(self.data[img_name]) #opens image\n        image = np.array(Image.open(io.BytesIO(image)),dtype=np.float32)/255\n\n        label = int(self.metadata['target'].iloc[idx]) #find the label \n        \n        if self.transform:\n            augmented = self.transform(image=image) #transformation \n            image = augmented['image'] #grab the augmented image \n\n        return image, label #if you want to include metadata we would need to return more fields here   \ndataset = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\ntrain_data = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n# Train Transform can be tailored according to the needs. Or it can None\ntrain_transform = A.Compose([\n    A.Resize(height=224, width=224), #resize \n    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n             A.RandomBrightnessContrast() \n             ], p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])\n\n#calls the custom dataset to access training data \ntrain_dataset = HDF5Dataset(dataset, train_data, transform=train_transform) \n#load training data \ntrain_loader = DataLoader(train_dataset,\n                          batch_size=32,\n                          shuffle=True,\n#                           sampler = sampler,\n                          num_workers=4) ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T07:37:11.133455Z","iopub.execute_input":"2024-08-24T07:37:11.134503Z","iopub.status.idle":"2024-08-24T07:37:20.368580Z","shell.execute_reply.started":"2024-08-24T07:37:11.134466Z","shell.execute_reply":"2024-08-24T07:37:20.367505Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1763307054.py:13: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  self.metadata = pd.read_csv(metadata)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import efficientnet_b0\n\neff = efficientnet_b0(pretrained = True)\n\nnum_features = eff.classifier[1].in_features\neff.classifier = nn.Sequential(\n#     nn.Dropout(p=0.5, inplace=True),\n    nn.Linear(num_features, 512),\n    nn.ReLU(),\n#     nn.Dropout(p=0.5, inplace=True),\n    nn.Linear(512, 128),\n    nn.ReLU(),\n#     nn.Dropout(p=0.5, inplace=True),\n    nn.Linear(128, 1),\n    nn.Sigmoid()\n)\n\nprint(num_features)\n\nfor param in eff.parameters():\n    param.requires_grad = True\n\nfor param in eff.features.parameters():\n    param.requires_grad = False\n\neff = eff.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T18:37:13.947472Z","iopub.execute_input":"2024-08-23T18:37:13.948332Z","iopub.status.idle":"2024-08-23T18:37:14.652033Z","shell.execute_reply.started":"2024-08-23T18:37:13.948296Z","shell.execute_reply":"2024-08-23T18:37:14.651014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lossfx = nn.BCELoss()\nlossfx.to(device)\noptimizer = torch.optim.Adam(eff.parameters(), lr = 0.0005)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T21:31:46.194592Z","iopub.execute_input":"2024-08-21T21:31:46.195244Z","iopub.status.idle":"2024-08-21T21:31:46.201774Z","shell.execute_reply.started":"2024-08-21T21:31:46.195208Z","shell.execute_reply":"2024-08-21T21:31:46.200907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Epoch = 5\nfor epoch in tqdm(range(Epoch)):\n    net_loss = 0.0\n    eff.train()\n    for image, label in tqdm(train_loader):\n#         x = data['image'].to(device)\n#         y = data['label'].to(device)\n        x = image.to(device)\n        y = label.to(device)\n        pred = eff(x)\n        loss_ = lossfx(pred.squeeze(), y.type(torch.float))\n#         net_loss += loss_.item()\n        del x\n        del y\n        optimizer.zero_grad()\n        loss_.backward()\n        optimizer.step()\n        torch.cuda.empty_cache()\n    print(f\"Epoch {epoch+1}\")\n#     mdl.eval()\n#     with torch.inference_mode():\n#         for data in tqdm(val_load):\n#             x = data['image'].to(device)\n#             y = data['label'].to(device)\n#             pred = mdl(x)\n#             acc.update(pred, y)\n#         print(f\"Validation Accuracy - {acc.compute()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T21:31:49.842443Z","iopub.execute_input":"2024-08-21T21:31:49.843305Z","iopub.status.idle":"2024-08-21T21:32:13.496454Z","shell.execute_reply.started":"2024-08-21T21:31:49.843269Z","shell.execute_reply":"2024-08-21T21:32:13.494918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save({'model_state_dict':eff.state_dict(),\n            'arch':'efficientnet_b0'},\n            'eff_b0_3.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}