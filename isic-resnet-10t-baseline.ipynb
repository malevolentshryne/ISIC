{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-03T09:13:59.232219Z","iopub.execute_input":"2024-08-03T09:13:59.233039Z","iopub.status.idle":"2024-08-03T09:15:17.007931Z","shell.execute_reply.started":"2024-08-03T09:13:59.233009Z","shell.execute_reply":"2024-08-03T09:15:17.006028Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/isic-2024-challenge/sample_submission.csv\n/kaggle/input/isic-2024-challenge/train-metadata.csv\n/kaggle/input/isic-2024-challenge/test-metadata.csv\n/kaggle/input/isic-2024-challenge/test-image.hdf5\n/kaggle/input/isic-2024-challenge/train-image.hdf5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirname, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, filename))\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 419\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 419\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 419\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_path \u001b[38;5;129;01min\u001b[39;00m walk_dirs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:377\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     is_dir \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# If is_dir() raises an OSError, consider that the entry is not\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# a directory, same behaviour than os.path.isdir().\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     is_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torchmetrics\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nfrom PIL import Image\nfrom torchvision import transforms\nfrom tqdm.notebook import tqdm_notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:15.638283Z","iopub.execute_input":"2024-08-04T20:27:15.638654Z","iopub.status.idle":"2024-08-04T20:27:24.848900Z","shell.execute_reply.started":"2024-08-04T20:27:15.638624Z","shell.execute_reply":"2024-08-04T20:27:24.848026Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:24.851193Z","iopub.execute_input":"2024-08-04T20:27:24.853587Z","iopub.status.idle":"2024-08-04T20:27:24.883277Z","shell.execute_reply.started":"2024-08-04T20:27:24.853544Z","shell.execute_reply":"2024-08-04T20:27:24.882269Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport h5py,io\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass HDF5Dataset(Dataset): #defining the dataset \n    def __init__(self, data, metadata, transform=None):\n        self.data = h5py.File(data, 'r') #creating data argument\n        if type(metadata) is pd.DataFrame:\n            self.metadata = metadata\n        else:\n            self.metadata = pd.read_csv(metadata)\n        self.transform = transform #creating transform argument \n\n    def __len__(self):\n        return len(self.metadata) #returns dataset \n\n    def __getitem__(self, idx):#gets image and label \n        img_name = self.metadata.isic_id[idx] #accesses image filepath \n        image = np.array(self.data[img_name]) #opens image\n        image = np.array(Image.open(io.BytesIO(image)),dtype=np.float32)/255\n\n        label = int(self.metadata['target'].iloc[idx]) #find the label \n\n        if self.transform:\n            augmented = self.transform(image=image) #transformation \n            image = augmented['image'] #grab the augmented image \n\n        return image, label #if you want to include metadata we would need to return more fields here   \n\ndataset = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\ntrain_data = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n# Train Transform can be tailored according to the needs. Or it can None\ntrain_transform = A.Compose([\n    A.Resize(height=224, width=224), #resize \n    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n             A.RandomBrightnessContrast() \n             ], p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])\n\n#calls the custom dataset to access training data \ntrain_dataset = HDF5Dataset(dataset, train_data, transform=train_transform) \n#load training data \ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4) ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:30.539469Z","iopub.execute_input":"2024-08-04T20:27:30.540339Z","iopub.status.idle":"2024-08-04T20:27:38.854605Z","shell.execute_reply.started":"2024-08-04T20:27:30.540305Z","shell.execute_reply":"2024-08-04T20:27:38.853612Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2814403026.py:13: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  self.metadata = pd.read_csv(metadata)\n","output_type":"stream"}]},{"cell_type":"code","source":"def conv_block(in_channels, out_channels, ker = 3, strd = 1, pad = 1,  pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=ker, stride = strd, padding=pad), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:38.856592Z","iopub.execute_input":"2024-08-04T20:27:38.857404Z","iopub.status.idle":"2024-08-04T20:27:38.863259Z","shell.execute_reply.started":"2024-08-04T20:27:38.857368Z","shell.execute_reply":"2024-08-04T20:27:38.862360Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Resnet_10t(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.b1 = nn.Sequential(\n            conv_block(3, 24, strd = 2),\n            conv_block(24, 32),\n            conv_block(32, 64),\n            nn.MaxPool2d(3, 2, 1)\n        )\n        self.b2 = nn.Sequential(\n            conv_block(64, 64),\n            conv_block(64, 64)\n        )\n        self.b3 = nn.Sequential(\n            conv_block(64, 128, strd = 2),\n            nn.Conv2d(128, 128, 3, 1, 1),\n            nn.BatchNorm2d(128)\n        )\n        self.d1 = nn.Sequential(\n            nn.AvgPool2d(2, 2),\n            nn.Conv2d(64, 128, 1, stride = 1),\n            nn.BatchNorm2d(128)\n        )\n        self.b4 = nn.Sequential(\n            conv_block(128, 256, strd = 2),\n            nn.Conv2d(256, 256, 3, 1, 1),\n            nn.BatchNorm2d(256)\n        )\n        self.d2 = nn.Sequential(\n            nn.AvgPool2d(2, 2),\n            nn.Conv2d(128, 256, 1, stride = 1),\n            nn.BatchNorm2d(256)\n        )\n        self.b5 = nn.Sequential(\n            conv_block(256, 512, strd = 2),\n            nn.Conv2d(512, 512, 3, 1, 1),\n            nn.BatchNorm2d(512)\n        )\n        self.d3 = nn.Sequential(\n            nn.AvgPool2d(2, 2),\n            nn.Conv2d(256, 512, 1, stride = 1),\n            nn.BatchNorm2d(512)\n        )\n        self.rel = nn.ReLU()\n        self.khatam = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Flatten(),\n            nn.Linear(512, 2)\n        )\n    def forward(self, x):\n        x = self.b1(x)\n        x = self.b2(x)\n        x1 = self.b3(x)\n        x2 = self.d1(x)\n        x = self.rel(x1 + x2)\n        x1 = self.b4(x)\n        x2 = self.d2(x)\n        x = self.rel(x1 + x2)\n        x1 = self.b5(x)\n        x2 = self.d3(x)\n        x = self.rel(x1 + x2)\n        x = self.khatam(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:38.864518Z","iopub.execute_input":"2024-08-04T20:27:38.865101Z","iopub.status.idle":"2024-08-04T20:27:38.879573Z","shell.execute_reply.started":"2024-08-04T20:27:38.865070Z","shell.execute_reply":"2024-08-04T20:27:38.878636Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cnn = Resnet_10t()\ncnn.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:40.662631Z","iopub.execute_input":"2024-08-04T20:27:40.663342Z","iopub.status.idle":"2024-08-04T20:27:40.896160Z","shell.execute_reply.started":"2024-08-04T20:27:40.663310Z","shell.execute_reply":"2024-08-04T20:27:40.895191Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Resnet_10t(\n  (b1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (b2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (b3): Sequential(\n    (0): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (d1): Sequential(\n    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (b4): Sequential(\n    (0): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (d2): Sequential(\n    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (b5): Sequential(\n    (0): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (d3): Sequential(\n    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (rel): ReLU()\n  (khatam): Sequential(\n    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): Linear(in_features=512, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"lossfx = nn.CrossEntropyLoss()\nlossfx.to(device)\noptimizer = torch.optim.NAdam(cnn.parameters(), lr = 0.0005)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:45.048534Z","iopub.execute_input":"2024-08-04T20:27:45.048878Z","iopub.status.idle":"2024-08-04T20:27:45.054878Z","shell.execute_reply.started":"2024-08-04T20:27:45.048853Z","shell.execute_reply":"2024-08-04T20:27:45.053592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"Epoch = 20\nfor epoch in tqdm(range(Epoch)):\n    net_loss = 0.0\n    cnn.train()\n    for image, label in tqdm(train_loader):\n#         x = data['image'].to(device)\n#         y = data['label'].to(device)\n        x = image.to(device)\n        y = label.to(device)\n        pred = cnn(x)\n        loss_ = lossfx(pred, y)\n        net_loss += loss_.item()\n        optimizer.zero_grad()\n        loss_.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1} | Loss - {net_loss/len(train_loader)}\")\n#     mdl.eval()\n#     with torch.inference_mode():\n#         for data in tqdm(val_load):\n#             x = data['image'].to(device)\n#             y = data['label'].to(device)\n#             pred = mdl(x)\n#             acc.update(pred, y)\n#         print(f\"Validation Accuracy - {acc.compute()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:27:49.530969Z","iopub.execute_input":"2024-08-04T20:27:49.531957Z","iopub.status.idle":"2024-08-04T20:31:12.587062Z","shell.execute_reply.started":"2024-08-04T20:27:49.531917Z","shell.execute_reply":"2024-08-04T20:31:12.585607Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ea05eb76914823b9d06188b6cb924d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12534 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842109ae4d864205a23eb547c27800fe"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss_ \u001b[38;5;241m=\u001b[39m lossfx(pred, y)\n\u001b[1;32m     12\u001b[0m net_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 51\u001b[0m, in \u001b[0;36mResnet_10t.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2(x)\n\u001b[1;32m     53\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb3(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# from torch.utils.data import Dataset, DataLoader\n# from PIL import Image\n# import h5py,io\n# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n\n# class HDF5Dataset(Dataset): #defining the dataset \n#     def __init__(self, data, metadata, transform=None):\n#         self.data = h5py.File(data, 'r') #creating data argument\n#         if type(metadata) is pd.DataFrame:\n#             self.metadata = metadata\n#         else:\n#             self.metadata = pd.read_csv(metadata)\n#         self.transform = transform #creating transform argument \n\n#     def __len__(self):\n#         return len(self.metadata) #returns dataset \n\n#     def __getitem__(self, idx):#gets image and label \n#         img_name = self.metadata.isic_id[idx] #accesses image filepath \n#         image = np.array(self.data[img_name]) #opens image\n#         image = np.array(Image.open(io.BytesIO(image)),dtype=np.float32)/255\n\n# #         label = int(self.metadata['target'].iloc[idx]) #find the label \n\n#         if self.transform:\n#             augmented = self.transform(image=image) #transformation \n#             image = augmented['image'] #grab the augmented image \n\n#         return image #if you want to include metadata we would need to return more fields here   \n# test_dataset = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n# test_data = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n# # Train Transform can be tailored according to the needs. Or it can None\n# test_transform = A.Compose([\n#     A.Resize(height=224, width=224), #resize \n#     # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n#     A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n#     ToTensorV2(),\n# ])\n\n# #calls the custom dataset to access training data \n# test_dataset = HDF5Dataset(test_dataset, test_data, transform=test_transform) \n# #load training data \n# test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T09:27:11.661052Z","iopub.execute_input":"2024-08-03T09:27:11.661361Z","iopub.status.idle":"2024-08-03T09:27:11.667344Z","shell.execute_reply.started":"2024-08-03T09:27:11.661330Z","shell.execute_reply":"2024-08-03T09:27:11.666500Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# predictions = []","metadata":{"execution":{"iopub.status.busy":"2024-08-03T09:27:11.668305Z","iopub.execute_input":"2024-08-03T09:27:11.668551Z","iopub.status.idle":"2024-08-03T09:27:11.682368Z","shell.execute_reply.started":"2024-08-03T09:27:11.668519Z","shell.execute_reply":"2024-08-03T09:27:11.681658Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# cnn.eval()\n# with torch.inference_mode():\n#     for image in tqdm(test_loader):\n#         x = image.to(device)\n#         y = label.to(device)\n#         pred = cnn(x)\n#         predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T09:27:11.684421Z","iopub.execute_input":"2024-08-03T09:27:11.684993Z","iopub.status.idle":"2024-08-03T09:27:11.692269Z","shell.execute_reply.started":"2024-08-03T09:27:11.684969Z","shell.execute_reply":"2024-08-03T09:27:11.691313Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# predictions","metadata":{"execution":{"iopub.status.busy":"2024-08-03T09:27:11.693294Z","iopub.execute_input":"2024-08-03T09:27:11.693561Z","iopub.status.idle":"2024-08-03T09:27:11.701633Z","shell.execute_reply.started":"2024-08-03T09:27:11.693532Z","shell.execute_reply":"2024-08-03T09:27:11.700824Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"torch.save(cnn.state_dict(), 'resnet_10t_params.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T09:27:11.702648Z","iopub.execute_input":"2024-08-03T09:27:11.702985Z","iopub.status.idle":"2024-08-03T09:27:11.760272Z","shell.execute_reply.started":"2024-08-03T09:27:11.702955Z","shell.execute_reply":"2024-08-03T09:27:11.759513Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}