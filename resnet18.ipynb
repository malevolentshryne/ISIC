{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-08T07:00:03.018002Z","iopub.execute_input":"2024-08-08T07:00:03.018840Z","iopub.status.idle":"2024-08-08T07:02:57.863611Z","shell.execute_reply.started":"2024-08-08T07:00:03.018806Z","shell.execute_reply":"2024-08-08T07:02:57.862822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport torchmetrics\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torch.nn as nn\nfrom PIL import Image\nfrom torchvision import transforms\nfrom tqdm.notebook import tqdm_notebook as tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:06:20.207983Z","iopub.execute_input":"2024-08-21T08:06:20.208389Z","iopub.status.idle":"2024-08-21T08:06:29.766369Z","shell.execute_reply.started":"2024-08-21T08:06:20.208356Z","shell.execute_reply":"2024-08-21T08:06:29.765531Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:06:29.768438Z","iopub.execute_input":"2024-08-21T08:06:29.769244Z","iopub.status.idle":"2024-08-21T08:06:29.807052Z","shell.execute_reply.started":"2024-08-21T08:06:29.769210Z","shell.execute_reply":"2024-08-21T08:06:29.806140Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# class_sample_count = [100,1]\n# weights = 1 / torch.Tensor(class_sample_count)\n# weights = weights.double()\n# sampler = torch.utils.data.sampler.WeightedRandomSampler(\n# weights=weights,\n# num_samples=100000,\n# replacement=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:06:29.808301Z","iopub.execute_input":"2024-08-21T08:06:29.808605Z","iopub.status.idle":"2024-08-21T08:06:29.817758Z","shell.execute_reply.started":"2024-08-21T08:06:29.808580Z","shell.execute_reply":"2024-08-21T08:06:29.816945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport h5py,io\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nclass HDF5Dataset(Dataset): #defining the dataset \n    def __init__(self, data, metadata, transform=None):\n        self.data = h5py.File(data, 'r') #creating data argument\n        if type(metadata) is pd.DataFrame:\n            self.metadata = metadata\n        else:\n            self.metadata = pd.read_csv(metadata)\n        self.transform = transform #creating transform argument \n\n    def __len__(self):\n        return len(self.metadata) #returns dataset \n\n    def __getitem__(self, idx):#gets image and label \n        img_name = self.metadata.isic_id[idx] #accesses image filepath \n        image = np.array(self.data[img_name]) #opens image\n        image = np.array(Image.open(io.BytesIO(image)),dtype=np.float32)/255\n\n        label = int(self.metadata['target'].iloc[idx]) #find the label \n        \n        if self.transform:\n            augmented = self.transform(image=image) #transformation \n            image = augmented['image'] #grab the augmented image \n\n        return image, label #if you want to include metadata we would need to return more fields here   \n\ndataset = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\ntrain_data = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n# Train Transform can be tailored according to the needs. Or it can None\ntrain_transform = A.Compose([\n    A.Resize(height=224, width=224), #resize \n    A.OneOf([A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15),\n             A.RandomBrightnessContrast() \n             ], p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    # !!One needs to change the mean and std values to appropriate ones for this dataset.!!\n    A.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=1.0),\n    ToTensorV2(),\n])\n\n#calls the custom dataset to access training data \ntrain_dataset = HDF5Dataset(dataset, train_data, transform=train_transform) \n#load training data \ntrain_loader = DataLoader(train_dataset,\n                          batch_size=32,\n                          shuffle=True,\n#                           sampler = sampler,\n                          num_workers=4) ","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:06:29.818905Z","iopub.execute_input":"2024-08-21T08:06:29.819211Z","iopub.status.idle":"2024-08-21T08:06:37.455477Z","shell.execute_reply.started":"2024-08-21T08:06:29.819179Z","shell.execute_reply":"2024-08-21T08:06:37.454673Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3939658464.py:13: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  self.metadata = pd.read_csv(metadata)\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# from torchvision.models import resnet18, ResNet18_Weights\n\n# resnet18 = resnet18(weights = ResNet18_Weights.DEFAULT)\n\n# for param in resnet18.parameters():\n#     param.requires_grad=False\n\n# resnet18.fc=nn.Sequential(\n#     nn.Linear(512, 1),\n#     nn.Sigmoid()\n# )\n\n# for param in resnet18.fc.parameters():\n#     param.requires_grad = True\n\n# resnet18 = resnet18.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:06:37.457406Z","iopub.execute_input":"2024-08-21T08:06:37.457726Z","iopub.status.idle":"2024-08-21T08:06:37.462687Z","shell.execute_reply.started":"2024-08-21T08:06:37.457700Z","shell.execute_reply":"2024-08-21T08:06:37.461629Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import efficientnet_b0\n\neff = efficientnet_b0()\n\nfor param in eff.parameters():\n    param.requires_grad=False\n\neff.fc=nn.Sequential(\n    nn.LazyLinear(1),\n    nn.Sigmoid()\n)\n\nfor param in eff.fc.parameters():\n    param.requires_grad = True\n\neff = eff.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:08:33.291245Z","iopub.execute_input":"2024-08-21T08:08:33.292119Z","iopub.status.idle":"2024-08-21T08:08:33.627673Z","shell.execute_reply.started":"2024-08-21T08:08:33.292083Z","shell.execute_reply":"2024-08-21T08:08:33.626722Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n","output_type":"stream"}]},{"cell_type":"code","source":"lossfx = nn.BCELoss()\nlossfx.to(device)\noptimizer = torch.optim.NAdam(eff.parameters(), lr = 0.0005)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:08:38.412608Z","iopub.execute_input":"2024-08-21T08:08:38.412969Z","iopub.status.idle":"2024-08-21T08:08:38.420412Z","shell.execute_reply.started":"2024-08-21T08:08:38.412941Z","shell.execute_reply":"2024-08-21T08:08:38.419281Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def pauc(y_true, y_pred):\n#     min_tpr=0.8\n#     v_gt = abs(np.asarray(y_true)-1)\n#     v_pred = np.array([1.0 - x for x in y_pred])\n#     max_fpr = abs(1-min_tpr)\n#     partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n#     partial_auc = 0.5 * max_fpr*2 + (max_fpr - 0.5 * max_fpr*2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n#     return partial_auc","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:08:46.409248Z","iopub.execute_input":"2024-08-21T08:08:46.409879Z","iopub.status.idle":"2024-08-21T08:08:46.413832Z","shell.execute_reply.started":"2024-08-21T08:08:46.409846Z","shell.execute_reply":"2024-08-21T08:08:46.412917Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"Epoch = 3\nfor epoch in tqdm(range(Epoch)):\n    net_loss = 0.0\n    eff.train()\n    for image, label in tqdm(train_loader):\n#         x = data['image'].to(device)\n#         y = data['label'].to(device)\n        x = image.to(device)\n        y = label.to(device)\n        pred = eff(x)\n        loss_ = lossfx(pred, y)\n#         net_loss += loss_.item()\n        del x\n        del y\n        optimizer.zero_grad()\n        loss_.backward()\n        optimizer.step()\n        torch.cuda.empty_cache()\n    print(f\"Epoch {epoch+1}\")\n#     mdl.eval()\n#     with torch.inference_mode():\n#         for data in tqdm(val_load):\n#             x = data['image'].to(device)\n#             y = data['label'].to(device)\n#             pred = mdl(x)\n#             acc.update(pred, y)\n#         print(f\"Validation Accuracy - {acc.compute()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:09:33.284081Z","iopub.execute_input":"2024-08-21T08:09:33.284447Z","iopub.status.idle":"2024-08-21T08:09:34.288065Z","shell.execute_reply.started":"2024-08-21T08:09:33.284410Z","shell.execute_reply":"2024-08-21T08:09:34.286637Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb28e46972394bbe8a4730df5ab89abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12534 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b16178ee7e448dc94e0d489fa1a45a8"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m         y \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         pred \u001b[38;5;241m=\u001b[39m eff(x)\n\u001b[0;32m---> 11\u001b[0m         loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mlossfx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         net_loss += loss_.item()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3113\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3111\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3116\u001b[0m     )\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n","\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1000])) is deprecated. Please ensure they have the same size."],"ename":"ValueError","evalue":"Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1000])) is deprecated. Please ensure they have the same size.","output_type":"error"}]},{"cell_type":"code","source":"torch.save({'model_state_dict':eff.state_dict(),\n            'arch':'eff_b0'},\n            'eff_b0.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-10T20:30:32.428458Z","iopub.execute_input":"2024-08-10T20:30:32.429166Z","iopub.status.idle":"2024-08-10T20:30:32.509255Z","shell.execute_reply.started":"2024-08-10T20:30:32.429132Z","shell.execute_reply":"2024-08-10T20:30:32.508413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}